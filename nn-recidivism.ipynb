{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WHITE  ALCHY  JUNKY  SUPER  MARRIED  FELON  WORKREL  PROPTY  PERSON  MALE  \\\n",
      "2       1      1      0      1        1      0        1       0       0     1   \n",
      "3       1      0      0      1        1      0        0       0       0     1   \n",
      "6       1      0      0      1        0      0        1       0       0     1   \n",
      "10      1      0      0      0        0      0        1       0       0     0   \n",
      "11      0      0      0      0        0      1        0       0       0     1   \n",
      "\n",
      "    PRIORS  SCHOOL  RULE  AGE  TSERVD  RECID  \n",
      "2        0       7     2  441      30      0  \n",
      "3        0      11     0  303       4      0  \n",
      "6        1       9     1  276      43      1  \n",
      "10       0      14     0  329       9      0  \n",
      "11       0      10     0  277       8      0  \n",
      "4618\n"
     ]
    }
   ],
   "source": [
    "# Get and process input data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "var = dict([ (1, ('WHITE',1)),(2, ('ALCHY',1)),(3, ('JUNKY',1)),(4, ('SUPER',1)),\n",
    "                (5, ('MARRIED',1)),(6, ('FELON',1)),(7, ('WORKREL',1)),(8, ('PROPTY',1)),\n",
    "                (9, ('PERSON',1)),(10, ('MALE',1)),(11, ('PRIORS',2)),(13, ('SCHOOL',2)),\n",
    "                (15, ('RULE',2)),(17, ('AGE',3)),(20, ('TSERVD',3)),\n",
    "                (23, ('FOLLOW',2)),(25, ('RECID',1)),(26, ('TIME',2)),(28, ('FILE',1)) ] )\n",
    "\n",
    "def cleanData(data):\n",
    "    res = []\n",
    "    cols = [x[1][0] for x in var.items()] # Get the column names\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        \n",
    "        curLine = []\n",
    "        for i in xrange(len(line)):\n",
    "            if i+1 not in var:\n",
    "                continue\n",
    "            name, sz = var[i+1]            \n",
    "            curLine.append(int(line[i:i+sz]))\n",
    "        \n",
    "        res.append(curLine)\n",
    "    \n",
    "    ret = pd.DataFrame(data=res, columns=cols)\n",
    "    ret = ret[ret.FILE != 3] # Remove incomplete data points\n",
    "    \n",
    "    # Remove some irrelevant columns\n",
    "    del ret['TIME']\n",
    "    del ret['FILE']\n",
    "    del ret['FOLLOW']\n",
    "    return ret\n",
    "    \n",
    "\n",
    "raw_1978 = open('data/1978.txt','rb').readlines()\n",
    "raw_1980 = open('data/1980.txt','rb').readlines()\n",
    "\n",
    "\n",
    "d1978 = cleanData(raw_1978)\n",
    "d1980 = cleanData(raw_1980)\n",
    "\n",
    "print d1978.head()\n",
    "print len(d1978)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural network for CS 281\n",
    "# Reference: http://pybrain.org/docs/tutorial\n",
    "\n",
    "import pybrain\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.structure import SoftmaxLayer, TanhLayer\n",
    "from pybrain.datasets import ClassificationDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.utilities import percentError\n",
    "\n",
    "# Load the dataframe data into the pybrain data set\n",
    "np_d1978 = (d1978.values).astype(float)\n",
    "np.random.shuffle(np_d1978)\n",
    "cutoff = int(np_d1978.shape[0] * 0.3) # < cutoff is the test set, otherwise training set\n",
    "\n",
    "# Change to -1, 1 classificaiton\n",
    "# np_d1978[ (np_d1978[:, -1] == 0), -1 ] = -1\n",
    "\n",
    "print np_d1978[:5]\n",
    "# Normalize\n",
    "for c in xrange( np_d1978.shape[1] - 1):\n",
    "    c_sd = np.std(np_d1978[cutoff:, c])\n",
    "    c_mean = np.mean(np_d1978[cutoff:, c])\n",
    "    \n",
    "    np_d1978[cutoff:, c] = (np_d1978[cutoff:, c] - c_mean) / c_sd\n",
    "    \n",
    "    # Normalize the test set as well\n",
    "    np_d1978[:cutoff, c] = (np_d1978[:cutoff, c] - c_mean) / c_sd   \n",
    "\n",
    "testD = ClassificationDataSet(np_d1978.shape[1]-1, nb_classes=2, class_labels=['No', 'Yes'])\n",
    "trainD = ClassificationDataSet(np_d1978.shape[1]-1, nb_classes=2, class_labels=['No', 'Yes'])\n",
    "\n",
    "for r_idx in xrange(len(np_d1978)):\n",
    "    r = np_d1978[r_idx, :]\n",
    "    inD, outD = r[:-1], r[-1]\n",
    "    \n",
    "    if r_idx < cutoff:\n",
    "        testD.appendLinked(inD, outD)\n",
    "    else:\n",
    "        trainD.appendLinked(inD, outD)\n",
    "\n",
    "# net = buildNetwork(2, 3, 1, hiddenclass=TanhLayer, outclass=SoftmaxLayer)\n",
    "trainD._convertToOneOfMany(bounds=[0,1])\n",
    "testD._convertToOneOfMany(bounds=[0,1])\n",
    "\n",
    "print np_d1978[:5]\n",
    "print trainD['target']\n",
    "\n",
    "print trainD.calculateStatistics()\n",
    "print testD.calculateStatistics()\n",
    "\n",
    "\n",
    "resErr = []\n",
    "    \n",
    "for hid in xrange(7, 17, 100):\n",
    "    net = buildNetwork(trainD.indim, hid, trainD.outdim, bias=True)\n",
    "    t = BackpropTrainer(net, dataset=trainD)    \n",
    "\n",
    "    bestEpoch = None\n",
    "    bestErr = 101.\n",
    "\n",
    "    for ep in xrange(40):    \n",
    "    #     t.trainUntilConvergence(maxEpochs=2000)\n",
    "        t.trainEpochs(50)\n",
    "        testRes = t.testOnClassData(dataset=testD)\n",
    "        trnresult = percentError( t.testOnClassData(),\n",
    "                                  trainD['class'] )\n",
    "        tstresult = percentError( testRes, testD['class'] )\n",
    "\n",
    "        if tstresult < bestErr:\n",
    "            bestErr = tstresult\n",
    "            bestEpoch = ep\n",
    "    #     print np.mean(t.testOnClassData(dataset=testD) == testD['class']) \n",
    "        N1, N0 = 0, 0\n",
    "        c_1, c_0 = 0, 0\n",
    "        for i in xrange(len(testRes)):\n",
    "            if testD['class'][i] == 0:\n",
    "                N0 += 1\n",
    "                if testRes[i] == 0:\n",
    "                    c_0 += 1\n",
    "            else:\n",
    "                N1 += 1\n",
    "                if testRes[i] == 1:\n",
    "                    c_1 += 1\n",
    "\n",
    "        print 'Hidden layers:', ep\n",
    "        print 'Prop. of 1s:', sum(testRes)/float(len(testRes))\n",
    "        print '% of class 0 correct:', float(c_0)/float(N0)\n",
    "        print '% of class 1 correct:', float(c_1)/float(N1)\n",
    "\n",
    "    #     print testRes\n",
    "    #     print t.testOnClassData(dataset=testD)\n",
    "        print \"epoch: %4d\" % t.totalepochs, \\\n",
    "              \"  train acc: %5.2f%%\" % (100-trnresult), \\\n",
    "              \"  test acc: %5.2f%%\" % (100-tstresult)\n",
    "    \n",
    "    resErr.append( (bestErr, hid, bestEpoch) )\n",
    "    \n",
    "print sorted(resErr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
